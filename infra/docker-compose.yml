version: '3'

services:

  master:
    image: mjhea0/spark:2.4.1
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: ${EXTERNAL_IP}
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080

  worker:
    image: mjhea0/spark:2.4.1
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_PUBLIC_DNS: ${EXTERNAL_IP}
    depends_on:
      - master
    ports:
      - 8081:8081

  namenode:
    image: hdfs-namenode
    ports:
      - "9000:9000"
      - "50070:50070"
    volumes:
      - ./data:/hadoop/data
    environment:
      - "HADOOP_CONF_DIR=/etc/hadoop"
      - "USER=root"